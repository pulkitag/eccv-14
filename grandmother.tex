\section{Are there grandmother cells in CNNs?}
\label{sec:grand-mother}
Neuroscientists have conjectured that cells in the human brain which only respond to very specific and complex visual stimuli (such as the face of one's grandmother) are involved in object recognition.
These neurons are often referred to as \emph{grandmother cells} (GMC) \cite{Barlow,Grandmother}. Proponents of artificial neural networks have shown a great interest in reporting the presence of GMC-like filters for specific object classes in their networks (see, for example, the cat filter reported in \cite{GoogleCat}). More recently, for understanding feature representations in CNNs, \cite{Simonyan,DeConv} presented methods for finding locally optimal visual inputs for individual filters.
These methods isolate individual inputs that activate a filter, but do not characterize the \emph{distribution} of images that cause an individual filter to fire above a certain threshold.
If, for example, we wish to see if the network contains a GMC filter for the \emph{cat} class, then we should look for a particular filter that fires strongly on all cats and nothing else.
This criteria can be expressed as looking for a filter that has high \emph{precision} and high \emph{recall}.
That is, a GMC filter for class $C$ is a filter that has a high average precision when tasked with classifying inputs from class $C$ versus inputs from all other classes.

%Mathematically, this computation is expressed as finding the set of images $\mathcal{I}$ which maximally activate a single feature (i.e. find $i \in \mathcal{I}$ s.t. Feature-score(i) $\geq th$ $\forall i $, where $th$ is a threshold value). The distribution of class labels associated with this set of images ($\mathcal{I}$), defines the \textit{precision} of the feature. However, this distribution does not account for the \textit{recall}.  The presence/absence of GMC is a scientifically interesting question to pursue, but for recognition, we require features with both high precision and high recall. Consequently, we argue that if the goal is object recognition, then GMC for a particular object class should be interpreted as features with high AP and not just high precision. 
 
Further, the notion of GMC-like features is related to standard feature encodings for image classification.
Prior to the work of \cite{Kriz}, the dominant approaches for image and scene classification were based on either representing images as a bag of local descriptors (BoW), such as SIFT (e.g., \cite{SPM}), or by first finding a set of mid-level patches \cite{Mid1,Blocks} and then encoding images in terms of them. 
The problem of finding good mid-level patches is often posed as a search for a set of high recall discriminative templates. 
In this sense, mid-level patch discovery is the search for a set of GMC templates. 
The low-level BoW representation, in contrast, is a \emph{distributed code} in the sense that a single feature by itself is not discriminative, but a group of features taken together is.
Given this, it is interesting to investigate the CNN features to find the kind of representations they employ.

We perform our analysis in two phases using conv-5 features. In the first phase, we directly address the question of finding GMC filters by computing the AP of individual filters. Then, we determine the total number of filters required for achieving the same performance as using all the filters in order to assess how distributed the feature representation is.

\subsection{Finding Grandmother Cells}
\label{sub:class-specific-unit}
%Precision for each filter from layer 5 is computed in a way analogous to entropy computation described in \ref{sub:def-ent}. In the final step instead of computing the entropy, we compute Prob(Class $|$ Filter Activity $\geq$ threshold). We define the selectivity of a filter as the area under the precision curve. 

%For this computation we use ground truth bounding boxes taken from PASCAL VOC-2007 test challenge.
%From figure \ref{fig:ap} it is clear that for some classes such persons and bicycles there are indeed some very high precision filters, but for a lot of classes like sofa and horses no such filters exist. 

\begin{figure}[t!]
\centering
\subfloat{\includegraphics[scale=0.20]{images/gtbbox_pascal_prerec_pool5units.png}}
\caption{The precision-recall curves for the top five (based on AP) conv-5 filter responses on PASCAL-DET-GT. Red-Curves: Fine Tuned Network, Blue-Curves: Pre-Trained Network. For most classes, precision drops significantly even at modest recall values. \todo{update figure with PDF}}
\label{fig:ap}
\end{figure}

%\begin{figure}[t!]
%\centering
%\includegraphics[scale=0.20]{images/prob_sel_dims_top5.png}
%\caption{This plot shows the precision curve for the top 5 most selective filters taken from Alex-Net (Blue) and FT-Net(Red) for all PASCAL classes. Y-axis is the precision and X-axis is number of examples.}
%\label{fig:prob-sel}
%\end{figure}

\subsection{How distributed are the feature representations?}
\label{sub:how-many}
\begin{figure}[t!]
\centering
\includegraphics[scale=0.35]{images/how-many.pdf}
\caption{Illustration of the greedy strategy used for selecting filters. For each class, a linear SVM is trained after ``sp-max'' feature transformation described in section \ref{sub:imp-loc} is applied. ``sp-max''  reduces conv-5 features into a 256-D vector, wherein each dimension corresponds to one of the 256 conv-5 filters. The magnitude of individual dimensions of the weight vector learned by SVM is used as a proxy for determining the importance of each dimension. For the sake of clarity, this procedure is described using a 4-D weight vector shown on the extreme left (the numbers on each bar are the dimension). Firstly, we take the absolute value for each dimension and then sort the dimensions based on this value. Then, we chose the top k filters/dimensions from this ranked list to construct a subset of size k.}
\label{fig:sel-strategy}
\end{figure}

In addition to visualizing the AP curves of individual filters, we measured the number of filters required to recognize objects of a particular class.
Feature selection was performed to construct nested subsets of filters, ranging from a single filter to all filters, using the greedy strategy described in Figure \ref{fig:sel-strategy}.\footnote{Filter subsets of size [1, 2, 3, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 80, 100, 128, 256] were used.}
The variation in performance with the number of filters is shown in figure \ref{fig:svm-sel-dims}. 

\begin{figure}[t!]
\centering
%\includegraphics[height=6.5cm]{images/svm_seldims.png}
\includegraphics[height=6.5cm]{images/pool5_spmax_num_svm_filters.pdf}
\caption{ The fraction of complete performance (Y-Axis) on PASCAL-DET-GT achieved by conv-5 filter subsets of different sizes (X-axis). Complete performance is the AP computed by considering responses of all the filters. Notice, that for a few classes such as ``person'' and ``bicycle'' only a few filters are required, but for most classes substantially more number of filters are needed.}
\label{fig:svm-sel-dims}
\end{figure}  

\setlength{\tabcolsep}{1pt}
\begin{table}[t!]
\begin{center}
\caption{Number of filters required to achieve 50\% ,90\% of the complete performance on PASCAL-DET-GT using a CNN pre-trained on Imagenet and fine-tuned for PASCAL-DET using conv-5 features.}
\label{table:num-fil}
\tiny
\begin{tabular}{lc||cccccccccccccccccccc}
\hline\noalign{\smallskip}
CNN & AP & aero & bike & bird & boat & bottle & bus & car & cat & chair & cow & table & dog & horse & mbike & person & plant & sheep & sofa & train & tv \\
\noalign{\smallskip}
\hline
pre-train & 50\% & 15 & 3 & 15 & 15 & 10 & 10 & 3 & 2 & 5 & 15 & 15 & 2 & 10 & 3 & 1 & 10 & 20 & 25 & 10 & 2 \\ 
fine-tune & 50\% & 10 & 1 & 20 & 15 & 5 & 5 & 2 & 2 & 3 & 10 & 15 & 3 & 15 & 10 & 1 & 5 & 15 & 15 & 5 & 2 \\
\hline
\noalign{\smallskip}
pre-train & 90\% & 40 & 35 & 80 & 80 & 35 & 40 & 30 & 20 & 35 & 100 & 80 & 30 & 45 & 40 & 15 & 45 & 50 & 100 & 45 & 25 \\
fine-tune & 90\% & 35 & 30 & 80 & 80 & 30 & 35 & 25 & 20 & 35 & 50 & 80 & 35 & 30 & 40 & 10 & 35 & 40 & 80 & 40 & 20 \\
\hline
\end{tabular}
\end{center}
\end{table}
\setlength{\tabcolsep}{1.4pt}
  
Table \ref{table:num-fil} lists the number of filters required to achieve 50\% and 90\% of the complete performance. For classes such as persons, cars, and cats relatively few filters are required, but for most classes around 30 to 40 filters are required to achieve at least 90\% of the full performance. This indicates that in conv-5, for a few classes (like cat and person) there are GMC-like filters, but for the most part the feature representation is distributed.
Results using layer fc-7 are presented in the the supplementary material.
We also find that after fine-tuning, slightly fewer filters are required to achieve performance levels similar to a pre-trained network. 

\begin{figure}[t!]
\centering
\includegraphics[width=1.0\linewidth]{images/ftNet_commonfilters.png}
\caption{The extent of overlap between the 50 most discriminative filters of conv-5 for each class determined using PASCAL-DET-GT.
Entry $(i, j)$ of the matrix is the fraction of top-50 filters class $i$ has in common with class $j$ (Section \ref{sub:how-many}). It can be seen, that there is little overlap between filters used for different classes.}
\label{fig:overlap}
\end{figure}

Next, we estimated the extent of overlap between the filters used for discriminating between different classes.
For each class $i$, we selected the 50 most discriminative filters (out of 256) and stored the selected filter indicies in the set $S_i$.
The extent of overlap between class $i$ and $j$ was evaluated by $(|S_i \cap S_j|) / N$,
where $N = |S_i| = |S_j| = 50$. The results are visualized in Figure \ref{fig:overlap}. It can be seen that different classes use different subsets of conv-5 filters and there is little overlap between classes. This further indicates that intermediate representations in CNN are distributed and different sets of are used to distinguish between different classes. 

