\section{Training Procedure}
\label{sec:train}
\subsection{Network-Architecture and Nomenclature}
\label{sub:net-arch}
We closely followed the CNN architecture proposed in \cite{Kriz} and publically available code of \cite{caffe} for all our experiments. The various layers of the CNN are organized as following: first 2 layers are subdivided into 4 sublayers each - convolution (conv), followed by rectified linear units (relu), pooling (pool) and contrast normalization (norm). Layers 3, 4 are composed of conv units followed by relu units. Layer 5 consists of conv units, followed by relu and pool units. The last two layers are fully connected (fc). In this work, when we refer to layers 1,2 and 5 we mean the output of pool units and for layers 3,4,6,7 we mean the output of relu units. The imagenet network was trained for 310000 iterations and achieved an error rate of only about 2\% higher on the ILSVRC validation set 2012. \newline
The term ImgNet is used to refer to a CNN trained for Imagenet classification. FT or FT-Net refers to a finetuned network whereas as FC-FT or FC-FT-Net refers to a network finetuned by setting the learning rate of the first 5 layers to zero. We use the terms CNNs and ConvNets interchangeably to refer to multilayer network architectures of the type proposed in \cite{Kriz}. Terms filter/unit are used interchangeably to refer to filters of the CNN and GT-BBOX/gt-bbox stands for Ground truth bounding boxes from the PASCAL-VOC-2007 detection challenge and mAP refers to mean average precision \cite{Pascal}.

\subsection{Training Setup} 
\label{sub:train-setup}
Results for image and GT-BBOX classification were obtained by training linear SVMs on train-val sets of PASCAL-VOC-2007 \cite{Pascal} and tested on the test set. For detection we closely follow the RCNN setup described in \cite{Rcnn}. For SUN-397 \cite{sun} we used a non-standard train-test splits since it was infeasible to finetune CNNs for 10 standard subsets proposed by \cite{sun}. Instead, we randomly split the dataset into 3 parts namely train,val and test using 50\%,10\% and 40\% of the data. The distribution of classes was uniform across all the 3 sets. Results on these splits are only used to support investigations into properties of CNNs and not for comparing against other scene-classification methods.  
 
\subsubsection{Fine-Tuning}
\label{sub:fine-train}
CNN were finetuned using SGD (Stochastic Gradient) with a starting learning rate set to $\frac{1}{10}^{th}$ of the initial learning rate used for training the network for Imagenet classification. This choice was made to prevent overfitting of CNNs to the new task for which the network was finetuned for. At every 20,000 iterations learning rate was reduced by a factor of 10 and mini-batch size of 128 was used. We closely followed \cite{Rcnn} for finetuning CNNs for object detection. 

\subsection{Method of Entropy Computation}
\label{sub:def-ent}
We define the entropy of a filter with respect to a given set of image-label pairs in the following way. Each image, when passed through the convolutional neural network produces a $p \times p$ heatmap of filter responses. (e.g. p = 6, for a layer 5 filter). We vectorize this heatmap into a vector of scores of length $p^2$ and with each element of this vector we associate the class label of the image. Thus, for each image we have a score vector and a label vector of length $p^2$ each. Next, we concatenate score vectors and label vectors from N images into a giant score vector and a giant label vector  of size $Np^2$ each. Now for every score threshold we consider all the labels which have an associated score $\geq$ to this threshold score. The entropy of this set of labels is the entropy of the filter at this threshold. As this threshold changes, entropy traces out a curve which we call as the entropy curve.  
