\begin{abstract}
In the last two years, convolutional neural networks (CNNs) have achieved an impressive suite of results on standard recognition datasets and tasks.
CNN-based features seem poised to quickly replace engineered representations, such as SIFT and HOG.
However, compared to SIFT and HOG, we understand much less about the nature of the features learned by large CNNs.
In this paper, we experimentally probe several aspects of CNN feature learning in an attempt to help practioners gain useful, evidence-backed intuitions about how to apply CNNs to computer vision problems.
%Towards this end, our paper is an empirical study addressing the following four questions: 
%(1) Does a multilayer CNN learn ``grandmother'' cells or a distributed representation?
%(2) How does fine-tuning affect performance and is pre-training still useful when more data becomes available? 
%(3) Does longer pre-training time hurt generalization performance?
%(4) How important is a feature's spatial location and its activation magnitude?

\keywords{convolutional neural networks, object recognition, empirical analysis}
\end{abstract}
