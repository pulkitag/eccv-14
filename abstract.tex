\begin{abstract}
In 2012 Krizhevsky et al. demonstrated that a Convolutional Neural Network (CNN) trained on large amount of data as part of the ImageNet challenge significantly outperformed computer vision approaches based on hand engineered features. Subsequently, Donahue et al. showed the general usefulness of CNN features on several classification datasets (DeCAF). Concurrently, Girshick et al. used CNN features computed on bottom-up region proposals to dramatically outperform existing object detection methods on PASCAL VOC and ImageNet detection (R-CNN). These results suggest that computer vision is undergoing a feature revolution akin to the one following SIFT and HOG nearly a decade ago. It is therefore important to gain insight into the features learned by these networks and better understand the behaviour of their training algorithms. Towards this direction, our paper is an empirical study addressing the following four questions: 
(1) What happens during fine-tuning of a discriminatively pretrained network? 
(2) How important is a feature's spatial location and its activation magnitude?
(3) Does a multilayer CNN contain ``grandmother'' cells?
(4) How does task performance vary as a function of CNN training time?

\keywords{convolutional neural networks, object recognition, empirical analysis}
\end{abstract}
