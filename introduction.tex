\section{Introduction}
The breakthrough work of \cite{Kriz} created a splash in the computer vision community by presenting a convolutional neural network (CNN) model which easily surpassed all existing methods on the ImageNet ILSVRC-2012 image classification challenge \cite{imagenet}.  The top-5 error rates dropped by an exceptional amount to 16.4\% from  26.2 \% (achieved by the second best alternative.) At that time, it was unclear if these networks would be useful for other computer vision tasks. A few months later, \cite{Decaf} demonstrated that features learnt by such networks generalize and achieve state of the art results on image classification challenges such as SUN-397\cite{sun}, Caltech-UCSD Birds and Caltech-101. 

More recently, features extracted using CNNs were used to achieve impressive results on object detection (RCNN \cite{Rcnn}) which dwarf the existing state of art by a big margin. \cite{Rcnn} achieved a mAP of 54.1 v/s 41.7 achieved by \cite{regionlets} on the PASCAL VOC 2007 detection challenge. Given that over the last few years, negligible progress was made on various PASCAL VOC challenges, these results are significant and strongly suggest that we might be in the middle of a feature revolution akin to the one ushered by introduction of HOG \cite{Hog} and SIFT \cite{Sift} in the mid 2000s.  

It is not the first time that CNN have generated great interest within the computer vision community. In late eighties LeNet\cite{Lecun89} achieved state of art performance on the task of MNIST digit classification. However, by late nineties interest in neural networks started to wane. One major reason was that a large number of parameters such as the number of layers, number of units in each layer, the learning rate needed to be manually set in order to successfully train these networks. Support Vector Machines (SVMs) on the other hand provided an easy alternative for achieving the same performance levels with only one parameter (C) to tune. Presently, given the impressive performance of CNN \cite{Kriz, Decaf, Rcnn} - the stage is all set for their second renaissance in mainstream computer vision. 

We take the view that rich feature hierarchies provided by CNN are very likely to emerge as the prominent feature extractor for computer vision models over the next few years. Feature extractors such as SIFT and HOG afford an intuitive interpretation of templates composed of oriented edge filters. However, we have little understanding of what visual features do the different layers of a CNN encode and what is the best way of using this information. We believe that developing such an understanding is an interesting scientific pursuit and an essential exercise prior to designing computer vision methods which can optimally use these features.

In this paper we address some of these issues through an empirical scientific investigation of multilayer CNNs. We characterize the features obtained from different layers by first teasing apart the importance of the magnitude and location of filter responses (sec \ref{sec-where-info}). We report that CNNs naturally provide sparse binary features and that for image classification the location of filter responses in the intermediate layers is not critical. Further, we establish an objective methodology for studying the question of how distributed are the feature representations and whether there are Grandmother Cell (\cite{Barlow, Grandmother}) like filters in the CNN  (sec \ref{sec:grand-mother}. We find that feature representations are distributed and only for a few classes the CNN develops Grandmother Cell like filters.  

Proponents of multilayer networks have argued in the past that unsupervised pre-training followed by finetuning is helpful for learning features which improve performance on discriminative tasks such as image classification \cite{GoogleCat, DeepPre, HintonPre}. Finetuning a network is the process of slowly updating pre-learned parameters to minimize a target loss function for a new task at hand. Since, multilayer networks consist of a large number of parameters they are prone to overfitting when trained on small datasets. Instead of unsupervised pre-training, \cite{Decaf, Rcnn} have made a strong case for learning features using discriminative pre-training followed by finetuning for a specific task at hand. They first trained a network for the task of image classification on Imagenet and then finetuned the network for object detection on PASCAL. In this work, we analyse the effect of finetuning on different layers of a CNN (section \ref{sec:fine}). We find that for moderately sized datasets (upto $\sim$ 50K images), finetuning only effects the top two fully connected layers (section \ref{sub:net-arch}) whereas the lower convolutional layers are mostly unchanged. We show that this observation can be used to make finetuning 2x faster with negligible effect on performance. We also demonstrate that a network can be trained from scratch using data only from the PASCAL dataset to achieve the state of art performance on object detection reported by \cite{Rcnn}. Further, by simply using more data for finetuning, we report a $10\%$ increase in performance for object detection over \cite{Rcnn}. 

Finetuning can also be viewed as a method for transfer learning (NEED REF for transfer learning). It is interesting to draw a parallel between this and the way we humans learn. As children, we can easily learn new things but as we grow older it becomes harder. Similarly, it is possible that if CNNs are pretrained for too long, it becomes harder to generalize to a new task. In other words, pre-training can lead to overfitting and consequently lead to worse performance on a new task due to dataset bias \cite{datasetBias}. Thus, we are faced with the question - is there an optimal time for which pre-training should be carried out? Rather surprisingly, we find that fitting better to ImageNet allows lower generalization error when moving to other datasets (section \ref{sec:train}), i.e. pre-training more improves performance.